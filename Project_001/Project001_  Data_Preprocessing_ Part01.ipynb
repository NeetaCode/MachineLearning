{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!pip install librosa tensorflow\n",
        "!pip install numpy tensorflow\n",
        "!pip install gtts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avk-s8rlOwT5",
        "outputId": "1113779b-8db5-43a0-87e9-48ee18377fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.4.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.11.17)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OsSUZOw_v5SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers, optimizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pydub import AudioSegment\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "\n",
        "# Your specific imports\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "iz6L3UqMWePX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or5Qb9u8L4XU",
        "outputId": "9fe1790b-e6f8-43d7-f5af-b66ca6f9dcc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion complete. WAV files are saved in: /content/drive/MyDrive/WAV_Files_Recordings/hindi\n"
          ]
        }
      ],
      "source": [
        "#.MP3 to .WAV files\n",
        "# Specify the source directory containing your MP3 files\n",
        "source_directory = \"/content/drive/MyDrive/Recordings_MP3/hindi\"\n",
        "\n",
        "# Specify the destination directory for the WAV files\n",
        "destination_directory = \"/content/drive/MyDrive/WAV_Files_Recordings/hindi\"\n",
        "\n",
        "# Specify the file to keep track of converted files\n",
        "converted_file_path = \"/content/drive/MyDrive/TXT_Files_AccentConversions/converted_files.txt\"\n",
        "\n",
        "# Ensure the destination directory exists, or create it\n",
        "os.makedirs(destination_directory, exist_ok=True)\n",
        "\n",
        "# Initialize a set to keep track of converted filenames\n",
        "converted_files = set()\n",
        "\n",
        "# Check if the converted file tracking exists and load the converted filenames\n",
        "if os.path.exists(converted_file_path):\n",
        "    with open(converted_file_path, 'r') as file:\n",
        "        converted_files = set(file.read().splitlines())\n",
        "\n",
        "# Loop through the MP3 files in the source directory and convert them to WAV if not already converted\n",
        "for mp3_file in os.listdir(source_directory):\n",
        "    if mp3_file.endswith(\".mp3\") and mp3_file not in converted_files:\n",
        "        mp3_path = os.path.join(source_directory, mp3_file)\n",
        "        wav_file = os.path.splitext(mp3_file)[0] + \".wav\"\n",
        "        wav_path = os.path.join(destination_directory, wav_file)\n",
        "\n",
        "        # Convert MP3 to WAV using pydub\n",
        "        sound = AudioSegment.from_mp3(mp3_path)\n",
        "        sound.export(wav_path, format=\"wav\")\n",
        "\n",
        "        # Add the converted filename to the set\n",
        "        converted_files.add(mp3_file)\n",
        "\n",
        "# Save the updated set of converted filenames\n",
        "with open(converted_file_path, 'w') as file:\n",
        "    file.write('\\n'.join(converted_files))\n",
        "\n",
        "print(\"Conversion complete. WAV files are saved in:\", destination_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the Silences\n",
        "\n",
        "# Specify the source directory containing your input WAV files\n",
        "source_directory = \"/content/drive/MyDrive/WAV_Files_Recordings/turkish\"\n",
        "\n",
        "# Specify the destination directory for the processed WAV files\n",
        "destination_directory = \"/content/drive/MyDrive/Removed_Pauses/turkish\"\n",
        "\n",
        "# Specify the log file to store the record of processed files\n",
        "log_file = \"/content/drive/MyDrive/TXT_Files_AccentConversions/removingPauses_log.txt\"\n",
        "\n",
        "# Ensure the destination directory exists, or create it\n",
        "os.makedirs(destination_directory, exist_ok=True)\n",
        "\n",
        "# Function to remove silence from audio files\n",
        "def remove_silence(input_file, output_file):\n",
        "    audio = AudioSegment.from_wav(input_file)\n",
        "\n",
        "    # Split on silence with a threshold of -50 dBFS (adjust as needed)\n",
        "    audio_segments = split_on_silence(audio, silence_thresh=-50)\n",
        "\n",
        "    # Concatenate non-silent segments\n",
        "    processed_audio = sum(audio_segments)\n",
        "\n",
        "    # Export the processed audio to a new WAV file\n",
        "    processed_audio.export(output_file, format=\"wav\")\n",
        "\n",
        "# Function to log processed files\n",
        "def log_processed_file(log_file, input_file, output_file):\n",
        "    with open(log_file, 'a') as log:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        log.write(f\"{timestamp} - Processed: {input_file} -> {output_file}\\n\")\n",
        "\n",
        "# Loop through the WAV files in the source directory and process them\n",
        "for wav_file in os.listdir(source_directory):\n",
        "    if wav_file.endswith(\".wav\"):\n",
        "        wav_path = os.path.join(source_directory, wav_file)\n",
        "        output_path = os.path.join(destination_directory, wav_file)\n",
        "\n",
        "        # Remove silence from the audio file\n",
        "        remove_silence(wav_path, output_path)\n",
        "\n",
        "        # Log the processed file\n",
        "        log_processed_file(log_file, wav_path, output_path)\n",
        "\n",
        "print(\"Silence removal complete. Processed WAV files are saved in:\", destination_directory)\n",
        "print(\"Processing log is saved in:\", log_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17lpW6HK0Mlj",
        "outputId": "44f35dde-548c-4f9a-d725-d882dbdbc565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silence removal complete. Processed WAV files are saved in: /content/drive/MyDrive/Removed_Pauses/turkish\n",
            "Processing log is saved in: /content/drive/MyDrive/TXT_Files_AccentConversions/removingPauses_log.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making Spectrograms\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Specify the source directory containing your WAV files\n",
        "source_directory = \"/content/drive/MyDrive/Removed_Pauses/turkish\"\n",
        "\n",
        "# Specify the destination directory for saving spectrogram images\n",
        "destination_directory = \"/content/drive/MyDrive/Spectrograms_Accent_Detection/turkish\"\n",
        "\n",
        "# Specify the path for tracking processed files\n",
        "processed_files_path = \"/content/drive/MyDrive/TXT_Files_AccentConversions/spectrograms_log.txt\"\n",
        "\n",
        "# Set the batch size (adjust as needed)\n",
        "batch_size = 100\n",
        "\n",
        "# Create or load the list of already processed files\n",
        "processed_files = set()\n",
        "\n",
        "if os.path.exists(processed_files_path):\n",
        "    with open(processed_files_path, \"r\") as file:\n",
        "        processed_files.update(file.read().splitlines())\n",
        "\n",
        "# Function to convert a list of WAV files to spectrogram images\n",
        "def batch_wav_to_spectrogram(wav_files, destination_directory):\n",
        "    for wav_file in wav_files:\n",
        "        if wav_file.endswith(\".wav\") and wav_file not in processed_files:\n",
        "            # Load the WAV file\n",
        "            audio, sr = librosa.load(wav_file)\n",
        "\n",
        "            # Generate the spectrogram\n",
        "            spectrogram = np.abs(librosa.stft(audio))\n",
        "\n",
        "            # Convert the spectrogram to decibels\n",
        "            spectrogram_db = librosa.amplitude_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "            # Create a matplotlib figure\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='log')\n",
        "\n",
        "            # Save the spectrogram as an image (e.g., PNG)\n",
        "            spectrogram_filename = os.path.splitext(os.path.basename(wav_file))[0] + \"_spectrogram.png\"\n",
        "            spectrogram_path = os.path.join(destination_directory, spectrogram_filename)\n",
        "            plt.savefig(spectrogram_path, bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "\n",
        "            # Mark the file as processed\n",
        "            processed_files.add(wav_file)\n",
        "\n",
        "            # Save the list of processed files\n",
        "            with open(processed_files_path, \"a\") as file:\n",
        "                file.write(wav_file + \"\\n\")\n",
        "\n",
        "# Get a list of all WAV files in the source directory\n",
        "wav_files = [os.path.join(source_directory, f) for f in os.listdir(source_directory) if f.endswith(\".wav\")]\n",
        "\n",
        "# Process WAV files in batches\n",
        "for i in range(0, len(wav_files), batch_size):\n",
        "    batch = wav_files[i:i + batch_size]\n",
        "    batch_wav_to_spectrogram(batch, destination_directory)\n",
        "\n",
        "print(\"Spectrogram conversion complete. Spectrogram images are saved in:\", destination_directory)\n"
      ],
      "metadata": {
        "id": "_83COrH2g3wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ad82f5-3baa-411e-e885-16bc708f77fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram conversion complete. Spectrogram images are saved in: /content/drive/MyDrive/Spectrograms_Accent_Detection/turkish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(file_path, num_mfcc=13, n_fft=2048, hop_length=512):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "    return mfccs\n",
        "\n",
        "def process_and_save(input_folder, output_folder, log_file):\n",
        "    processed_files = []\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            input_file_path = os.path.join(input_folder, filename)\n",
        "            output_file_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.npy\")\n",
        "\n",
        "            # Check if the file has already been processed\n",
        "            if os.path.exists(output_file_path):\n",
        "                print(f\"Skipping {input_file_path} - Already processed\")\n",
        "                processed_files.append(output_file_path)\n",
        "                continue\n",
        "\n",
        "            mfcc = extract_mfcc(input_file_path)\n",
        "\n",
        "            # Pad or truncate MFCCs to a fixed length\n",
        "            if mfcc.shape[1] < 100:\n",
        "                mfcc = np.pad(mfcc, ((0, 0), (0, 100 - mfcc.shape[1])), mode='constant')\n",
        "            else:\n",
        "                mfcc = mfcc[:, :100]\n",
        "\n",
        "            np.save(output_file_path, mfcc)\n",
        "            print(f\"Processed {input_file_path} and saved to {output_file_path}\")\n",
        "            processed_files.append(output_file_path)\n",
        "\n",
        "    # Store the list of processed files in a text file\n",
        "    with open(log_file, 'w') as file:\n",
        "        for file_path in processed_files:\n",
        "            file.write(file_path + '\\n')\n",
        "\n",
        "    print(f\"\\nList of processed files saved to {log_file}\")\n",
        "    return log_file\n",
        "\n",
        "# Set your input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Removed_Pauses/turkish'\n",
        "output_folder = '/content/drive/MyDrive/MFCC_Features/turkish'\n",
        "log_file = '/content/drive/MyDrive/TXT_Files_AccentConversions/MFCClogfile.txt'\n",
        "\n",
        "# Process and save files\n",
        "processed_log_file = process_and_save(input_folder, output_folder, log_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz47kP3sgwL8",
        "outputId": "5d402d59-0ad7-4df3-acf7-de3eec015c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish11.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish11.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish12.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish12.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish15.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish15.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish1.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish1.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish14.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish14.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish10.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish10.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish13.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish13.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish21.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish21.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish16.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish16.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish17.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish17.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish19.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish19.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish18.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish18.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish20.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish20.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish2.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish2.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish26.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish26.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish22.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish22.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish7.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish7.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish34.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish34.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish37.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish37.npy\n",
            "Processed /content/drive/MyDrive/Removed_Pauses/turkish/turkish4.wav and saved to /content/drive/MyDrive/MFCC_Features/turkish/turkish4.npy\n",
            "\n",
            "List of processed files saved to /content/drive/MyDrive/TXT_Files_AccentConversions/MFCClogfile.txt\n"
          ]
        }
      ]
    }
  ]
}